---
name: "SLURM"
partition: "accelerated"
job-name: "toytask2d"
num_parallel_jobs: 120
ntasks: 1
cpus-per-task: 152
time: 960
#gpus_per_rep: 0.5
#scheduler: horeka
sbatch_args:
  gres: "gpu:4"
  account: "hk-project-sustainebot"
---
# cw2 config
repetitions: 1
reps_per_job: 1
reps_in_parallel: 1
iterations: &iterations 600
num_checkpoints: 2

# Global config
exp_path: &exp_path "./cw2_results/vdd/toytask2d"
exp_name: &exp_name "toytask2d"


# cw2 config
name: *exp_name
path: *exp_path
device: &device "cuda"
dtype: &dtype "float32"
seed:  &seed 0
enable_wandb: false

# wandb
wandb:
  project: "neurips_toytask2d"
  group: *exp_name
  entity: zhouhongyi
  log_interval: 10
  log_model: false
  model_name: model

params:
  gpu_id: 0
  policy_params:
    moe_params:
      obs_dim: &obs_dim 2
      act_dim: 2
      goal_dim: &goal_dim 0
      goal_conditional: &goal_conditional false
      num_components: 8
      cmp_cov_type: "diag"
      moe_network_type: "residual" # "mlp" or "residual"
      cmp_hidden_dims: 64
      cmp_hidden_layers: 2
      cmp_cov_hidden_dims: 64
      cmp_cov_hidden_layers: 2
      bias_init_bound: 0.5
      cmp_activation: "mish"
      cmp_init: 'orthogonal'
      cmp_init_std: 1.0
      cmp_minimal_std: 0.0001
      prior_type: "uniform"
      learn_gating: false
      gating_hidden_layers: 2
      gating_hidden_dims: 64
      greedy_predict: false
    #### Transformer
    backbone_params:
      use_transformer: false
      n_layers: 1
      window_size: &window_size 1
      goal_seq_len: &goal_seq_len 0
      n_heads: 2
      embed_dim: 16
      embed_pdrop: 0.0
      atten_pdrop: 0.0
      resid_pdrop: 0.0
    #### vision encoder params
    vision_task: false


  optimizer_params:
    optimizer_type: "adam"
    cmps_lr: 0.0005
    cmps_lr_schedule: "linear"
    cmps_weight_decay: 0.0
    gating_lr: 0.0001
    gating_lr_schedule: "linear"
    gating_weight_decay: 0.0

  train_params:
    max_train_iters: *iterations
    cmp_steps: 1
    gating_steps: 1
    fix_gating_after_iters: *iterations
    vi_batch_size: 64
    train_batch_size: &train_batch_size 32
    test_batch_size: &test_batch_size 32
#    num_workers: &num_workers 4
    test_interval: 10
    env_rollout_interval: 20
    num_rollouts: 4
    num_contexts: 10
    final_num_contexts: 60
    final_num_rollouts: 8
    device: *device
    dtype: *dtype

  experiment_params:
    experiment_name: "toytask2d"
    model_select_metric: "iter"
    num_datapoints: 5000
    datasets_config:
      batch_size: *train_batch_size
    score_fn_params:
      num_components: 8
      r: 2.0
      std: 0.5
    seed: *seed






