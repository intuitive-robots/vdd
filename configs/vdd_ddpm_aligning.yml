---
name: "SLURM"
partition: "accelerated"
job-name: "toytask2d"
num_parallel_jobs: 120
ntasks: 1
cpus-per-task: 152
time: 960
#gpus_per_rep: 0.5
#scheduler: horeka
sbatch_args:
  gres: "gpu:4"
  account: "hk-project-sustainebot"
---
# cw2 config
repetitions: 1
reps_per_job: 1
reps_in_parallel: 1
iterations: &iterations 40001
num_checkpoints: 2

# Global config
exp_path: &exp_path "./cw2_results/clean_vdd/avoiding"
exp_name: &exp_name "aligning_full_8cmp_realt4-4_bias0.2"


# cw2 config
name: *exp_name
path: *exp_path
device: &device "cuda"
dtype: &dtype "float32"
seed:  &seed 0
enable_wandb: true

# wandb
wandb:
  project: "cleanVDD_D3IL"
  group: *exp_name
  entity: zhouhongyi
  log_interval: 10
  log_model: false
  model_name: model

params:
  gpu_id: 0
  cpu_start_id: 0
  num_cpus: 8
  policy_params:
    moe_params:
      obs_dim: 20
      act_dim: 3
      goal_dim: 0
      goal_conditional: false
      num_components: 8
      moe_network_type: "residual" # "mlp" or "residual"
      cmp_cov_type: "full" # "full" or "diag"
      cmp_mean_hidden_dims: 512
      cmp_mean_hidden_layers: 2
      cmp_cov_hidden_dims: 512
      cmp_cov_hidden_layers: 2
      bias_init_bound: 0.2
      cmp_activation: "mish"
      cmp_init: 'orthogonal'
      cmp_init_std: 1.0
      cmp_minimal_std: 0.0001
      prior_type: "uniform"
      learn_gating: true
      gating_hidden_layers: 2
      gating_hidden_dims: 64
      greedy_predict: false
    #### Transformer
    backbone_params:
      use_transformer: true
      n_layers: 4
      window_size: &window_size 5
      goal_seq_len: 1
      n_heads: 4
      embed_dim: 72
      embed_pdrop: 0.0
      atten_pdrop: 0.2
      resid_pdrop: 0.1
    #### vision encoder params
    vision_task: false


  optimizer_params:
    optimizer_type: "adam"
    cmps_lr: 0.0001
    cmps_lr_schedule: "linear"
    cmps_weight_decay: 0.0
    gating_lr: 0.0001
    gating_lr_schedule: "linear"
    gating_weight_decay: 0.0

  train_params:
    max_train_iters: *iterations
    cmp_steps: 2
    gating_steps: 1
    fix_gating_after_iters: *iterations
    vi_batch_size: 2
    train_batch_size: &train_batch_size 1024
    test_batch_size: &test_batch_size 1024
    test_interval: 10
    env_rollout_interval: 2000
    num_rollouts: 5
    num_contexts: 8
    final_num_contexts: 60
    final_num_rollouts: 8
    device: *device
    dtype: *dtype

  experiment_params:
    experiment_name: "d3il_aligning"
    vision_task: false
    goal_conditioned: false
    model_path: "/home/hongyi/Codes/demo_acc_rl/d3il/logs/models/aligning/ddpm_gpt/agent_name=ddpm_transformer,agents.model.n_timesteps=16,agents=ddpm_transformer_agent,group=robot_push_ddpm_transformer_seeds,seed=0,simulation.n_contexts=60,simulation.n_cores=30,simulation.n_trajectories_per_context=8,window_size=5"
    sv_name: "eval_best_ddpm.pth"
    model_select_metric: "success_rate"
    datasets_config:
      train_batch_size: *train_batch_size
      test_batch_size: *test_batch_size
      window_size: *window_size
      goal_seq_len: 1
      num_workers: 1
    score_type: "ddpm"
    score_fn_params:
      noise_level_type: "discrete" # "uniform" or "discrete"
      weights_type: "stable"
      t_min: 4
      t_max: 4
      t_bound: 16
    obs_dim: 20
    goal_dim: 0
    seed: *seed